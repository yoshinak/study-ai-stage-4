{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day-4-4-models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOrCEFlqT2qVmuQ96nntejd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adnxs5kDc2pd"
      },
      "source": [
        "# (day4) Section 4: 応用モデル\n",
        "\n",
        "本書は、「深層学習後編（day4）レポート」の、「Section 4: 応用モデル」についてのものです。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_jMHYWudCh3"
      },
      "source": [
        "## 1. 要点まとめ\n",
        "\n",
        "実際のニューラルネットワークの例。\n",
        "\n",
        "- NOTE: シラバスに載っている他のネットワークについてもおさえておくこと。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- page. 75 - 107\n",
        "\n",
        "<!-- - MobileNets\n",
        "\n",
        "- DenseNet\n",
        "\n",
        "- 正規化\n",
        "  - Batch Norm\n",
        "  - Layer Norm\n",
        "  - Instance Norm\n",
        "\n",
        "- WaveNet -->\n"
      ],
      "metadata": {
        "id": "0kiWmQleVzAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNets\n",
        "\n",
        "画像認識において、軽量化したモデル。\n",
        "画像認識は、 2017 年に完成され技術となっており、以降は軽量化に重きをおいて研究されている。\n",
        "\n",
        "一般的な畳み込みレイヤーでは計算が多いことに対して、<br/>\n",
        "Depthwise Convolution と Pointwise Convolution の組み合わせで軽量化を実現したモデル。\n",
        "畳み込み演算を工夫している。\n"
      ],
      "metadata": {
        "id": "npySq0PDWzJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Depthwise Convolution\n",
        "\n",
        "kernel に工夫がある。\n",
        "\n",
        "- フィルター数は 1\n",
        "- 1 つのチャネルに、1 つのフィルター\n",
        "\n",
        "フィルター数分、計算量を削減。\n"
      ],
      "metadata": {
        "id": "51WYtYtOXuHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pointwise Convolution\n",
        "\n",
        "Kernel を $ 1 \\times 1 $ に固定する。\n",
        "\n",
        "Kernel の $ K \\times K $ 分の計算量を削減。\n"
      ],
      "metadata": {
        "id": "L1HUz88iXwY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### アーキテクチャ\n",
        "\n",
        "Depthwise Convolution の計算量は、フィルター数が 1 なので、<br/>\n",
        "$\n",
        "H \\times W \\times C \\times K \\times K\n",
        "$\n",
        "\n",
        "Pointwise Convolution の計算量は、 Kernel が $ 1 \\times 1 $ なので、<br/>\n",
        "$\n",
        "H \\times W \\times C \\times M\n",
        "$\n"
      ],
      "metadata": {
        "id": "pAVEIxGDYNfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "普通の畳み込みの計算量\n",
        "\n",
        "$$\n",
        "H \\times W \\times K \\times K \\times C \\times M\n",
        "$$\n",
        "\n",
        "に対して、 Depthwise Convolution と Pinthwise Convolution の和となって、\n",
        "\n",
        "$$\n",
        "H \\times W \\times C \\times K \\times K\n",
        "+\n",
        "H \\times W \\times C \\times M\n",
        "$$\n",
        "\n",
        "計算量を削減。\n"
      ],
      "metadata": {
        "id": "mj2stkezen-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- - NOTE: 畳み込み層の数式\n",
        "  - [畳み込みネットワークの「基礎の基礎」を理解する　～ディープラーニング入門｜第2回 - アイマガジン｜i Magazine｜IS magazine](https://www.imagazine.co.jp/%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E3%80%8C%E5%9F%BA%E7%A4%8E%E3%81%AE%E5%9F%BA%E7%A4%8E%E3%80%8D%E3%82%92%E7%90%86%E8%A7%A3%E3%81%99/)\n",
        "    > xが入力画像の各ピクセルの値、wが重み、bがバイアス、σが活性化関数<br/>\n",
        "    > ...\n",
        "    > （ここでは3×3の9ニューロン）\n",
        "\n",
        "$$\n",
        "\\sigma (\n",
        "  \\textbf{b} + \\sum_{l=0}^2 \\sum_{m=0}^2\n",
        "    \\textbf{w}_{l,m} \\textbf{x}_{j+l, k+m}\n",
        ")\n",
        "$$ -->\n"
      ],
      "metadata": {
        "id": "fNwVT7Ujgild"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DenseNet\n",
        "\n",
        "画像認識。\n"
      ],
      "metadata": {
        "id": "x4g_lLz5W1nh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DenseBlock\n",
        "\n",
        "DenseBlock というブロックの中にいくつかの層があり、層を通過する毎にチャネルが増える仕組み。\n",
        "さらに前のブロックの出力を足し合わせてある。\n"
      ],
      "metadata": {
        "id": "YiWT8y3TY_uY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Growth Rate\n",
        "\n",
        "チャンネルの増え方は以下の通り。\n",
        "\n",
        "$ k $ はチャンネルの数。\n",
        "\n",
        "4 回 DenseBlock のノードを通過すると、\n",
        "$\n",
        "k_0 + 4 k\n",
        "$\n"
      ],
      "metadata": {
        "id": "u1IUHAF-ZQOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transition Layer\n",
        "\n",
        "DenseBlock で増えたチャンネルを、畳み込み層とプーリング層で減らす。\n"
      ],
      "metadata": {
        "id": "76Eb8WIjZH0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ResNet ( ResidualBlock ) との違い\n",
        "\n",
        "同様にスキップ・コネクションを使っている ResNet との違いは、<br/>\n",
        "ResidualBlock では  1 つ前の層のみを使用していたが、<br/>\n",
        "DenseBlock では、前の全ての層の出力を使う。\n",
        "\n",
        "また、 Growth Rate でチャンネル数を増加させている。\n"
      ],
      "metadata": {
        "id": "AXxlNJNSZUUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 正規化\n"
      ],
      "metadata": {
        "id": "dajqZoczW3xY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Batch Norm\n",
        "\n",
        "標準分布に正規化。\n",
        "\n",
        "あまり実際には使いたくない手法。\n",
        "ミニバッチのサイズは、ハードウェアによって、変える必要がある。( メモリ量で影響 )\n",
        "よって、一定のミニバッチのサイズにできないため、固定サイズを基に比較ができないため。\n",
        "\n",
        "それで、以降の Layer Norm と Instance Norm の使用を検討する。\n"
      ],
      "metadata": {
        "id": "buvvKNp8W-lh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Layer Norm\n",
        "\n",
        "同じ層のニューロン間で正規化する。\n",
        "\n",
        "<!-- - https://arxiv.org/pdf/1607.06450.pdf -->\n"
      ],
      "metadata": {
        "id": "WIY-3RqpXACg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instance Norm\n",
        "\n",
        "チャンネル毎に正規化する。\n",
        "\n",
        "- [Batch Normalization, Instance Normalization, Layer Normalization: Structural Nuances | Becoming Human: Artificial Intelligence Magazine](https://becominghuman.ai/all-about-normalization-6ea79e70894b)<br/>\n",
        "  個々のサンプルの、個々のチャネルで正規化。 ( 空間軸は跨って )"
      ],
      "metadata": {
        "id": "PWq04YCjXD5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WaveNet\n",
        "\n",
        "音声生成モデル。\n"
      ],
      "metadata": {
        "id": "WU6NV7mAW41A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dilated convolution\n",
        "\n",
        "- https://arxiv.org/pdf/1609.03499.pdf<br/>\n",
        "  > 2.1 DILATED CAUSAL CONVOLUTIONS\n",
        "\n",
        "音声の信号を並べて、畳み込み演算を行って音声を扱う、通常のネットワークが、 \"Figure 2: Visualization of a stack of causal convolutional layers.\"\n",
        "\n",
        "これに対して、 dilated convolution は、層を通過するときに入力スキップする。<br/>\n",
        "( 引用元の \"Figure 3: Visualization of a stack of dilated causal convolutional layers\" )\n",
        "\n",
        "畳み込みニューラルネットワークで、 0 で拡張 ( パディング? ) した大きなフィルターを使うことに相当する仕組み。\n",
        "パラメータ数に対する ( ニューラルネットワークの ) 受容野を広げる目的。\n"
      ],
      "metadata": {
        "id": "200BwWfiZhzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NOTE: Deconvolution ( 例題に出てきた例 )\n",
        "  - https://arxiv.org/pdf/1905.11926.pdf<br/>\n",
        "    page. 2 の馬の画像の例。\n",
        "\n",
        "  <!-- - [Convolutions: Transposed and Deconvolution | by Mars Xiang | Medium](https://medium.com/@marsxiang/convolutions-transposed-and-deconvolution-6430c358a5b6) -->\n"
      ],
      "metadata": {
        "id": "tNSOIATVu8HE"
      }
    }
  ]
}